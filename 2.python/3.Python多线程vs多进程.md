# Python多线程vs多进程
> Python多进程加速，看这一篇就够了

## 线程 vs 进程
> 什么是线程、进程
> 线程和进程有什么差异
> 线程和进程应用场景
> Python的线程和进程实现机制

### 线程

​    **线程**是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。一个线程是一个execution context（执行上下文），即一个cpu执行时所需要的一串指令。

​    Eg. 假设你正在读一本书，没有读完，你想休息一下，但是你想在回来时恢复到当时读的具体进度。有一个方法就是记下页数、行数与字数这三个数值，这些数值就是execution context。如果你的室友在你休息的时候，使用相同的方法读这本书。你和她只需要这三个数字记下来就可以在交替的时间共同阅读这本书了。

线程的工作方式与此类似。CPU会给你一个在同一时间能够做多个运算的幻觉，实际上它在每个运算上只花了极少的时间，本质上CPU同一时刻只干了一件事。它能这样做就是因为它有每个运算的execution context。就像你能够和你朋友共享同一本书一样，多任务也能共享同一块CPU。

### 进程

​    一个程序的执行实例就是一个**进程**。每一个进程提供执行程序所需的所有资源。（进程本质上是资源的集合）

​    一个进程有一个虚拟的地址空间、可执行的代码、操作系统的接口、安全的上下文（记录启动该进程的用户和权限等等）、唯一的进程ID、环境变量、优先级类、最小和最大的工作空间（内存空间），还要有至少一个线程。每一个进程启动时都会最先产生一个线程，即主线程。然后主线程会再创建其他的子线程。

​    与进程相关的资源：

- 内存页（**同一个进程中的所有线程共享同一个内存空间**）
- 文件描述符(e.g. open sockets)
- 安全凭证（e.g.启动该进程的用户ID）

### 异同

- 进程是分配资源的最小单位，线程是系统调度的最小单位
- 同一个进程中的线程共享同一内存空间，但是进程之间是独立的
- 同一个进程中的所有线程的数据是共享的（进程通讯），进程之间的数据是独立的
- 对主线程的修改可能会影响其他线程的行为，但是父进程的修改（除了删除以外）不会影响其他子进程
- 线程是一个上下文的执行指令，而进程则是与运算相关的一簇资源
- 同一个进程的线程之间可以直接通信，但是进程之间的交流需要借助中间代理来实现
- 创建新的线程很容易，但是创建新的进程需要对父进程做一次复制
- 一个线程可以操作同一进程的其他线程，但是进程只能操作其子进程
- 线程启动速度快，进程启动速度慢（但是两者运行速度没有可比性）
- IO 密集型任务，任务越多，CPU效率越高. **适合于多线程处理**
- CPU密集型任务，适合多进程处理


## Python多线程

### 1. 线程常用方法

- start，线程准备就绪，等待CPU调研
- setName，为线程设置名称
- getName，获取线程名称
- setDaemon(True), 设置守护线程
- join(), 逐个执行每个线程，执行完毕后继续往下执行
- run()， 线程被CPU调度后，自动执行线程对象的run方法

### 2. 线程创建方式

#### 普通方式，借助Threading类

```python
# 存在问题
"""
	1. 最后一条语句，意外的会先执行，原因？如何处理？
	Cause:  sleep的时候是不会占用cpu的,在sleep的时候操作系统会把线程暂时挂起，因此先执行了后面的代码
	DealTo: 为每个子线程添加join，执行完之后，才会执行其他线程或者主线程，见第2段代码
"""

import threading
import time

def run(n):
    print("task %s" %n)
    time.sleep(1)
    print("2s")
    time.sleep(1)
    print("1s")
    time.sleep(1)
    print("0s")
    
    
    
if __name__ == "__main__":
    st = time.time()
    names = vars()
    for ts in range(1, 10):
        names["var_%d" %ts] = threading.Thread(target=run, args=("t%d" %ts, ))
        
    for ts in range(1, 10):
        names["var_%d" %ts].start()
    
    ed = time.time()
    
    print("cost time is %f" %(ed-st))
```

```python
import threading
import time

def run(n):
    print("task %s" %n)
    time.sleep(1)
    print("2s")
    time.sleep(1)
    print("1s")
    time.sleep(1)
    print("0s")
    
if __name__ == "__main__":
    st = time.time()
    t_obj = []   #定义列表用于存放子线程实例
    
    for ts in range(1, 10):
        t = threading.Thread(target=run, args=("t%d" %ts, ))
        t.start()
        t_obj.append(t)
        
    for t in t_obj:
        t.join()  #为每个子线程添加join之后，主线程就会等这些子线程执行完之后再执行
    
    ed = time.time()
    
    print("cost time is %f" %(ed-st))
    print(threading.current_thread())       #输出当前线程
```

#### 自定义线程类

> 继承threading.Thread，本质是重构Thread类的run方法
>
> 方法写在run里面

```python
import threading
import time
    
class selfThread(threading.Thread):
    def __init__(self, n):
        super(selfThread, self).__init__()  # 重构run函数必须要写
        self.n = n
    
    def run(self):
        print("task %s" %self.n)
        time.sleep(1)
        print("2s")
        time.sleep(1)
        print("1s")
        time.sleep(1)
        print("0s")
    
if __name__ == "__main__":
   
    st2 = time.time()
    
    t_lst = []
    for ts in range(1, 10):
        t = selfThread("t%d" %ts)
        t.start()
        t_lst.append(t)
        
    for t in t_lst:
        t.join()
    
    ed2 = time.time()
    print("cost time of Method2 is %f" %(ed2-st2))
```

### 3. 统计子线程数量

​        由于主线程比子线程慢很多，当主线程执行active_count()时，其他子线程都已经执行完毕，因此利用主线程统计的活跃的线程数num = 1(主线程本身)

```python
import threading
import time
    
class selfThread(threading.Thread):
    def __init__(self, n):
        super(selfThread, self).__init__()  # 重构run函数必须要写
        self.n = n
    
    def run(self):
        print("task %s" %self.n)
        time.sleep(1)
        print("2s")
        time.sleep(1)
        print("1s")
        time.sleep(1)
        print("0s")
    
if __name__ == "__main__":
   
    st2 = time.time()
    
    t_lst = []
    for ts in range(1, 10):
        t = selfThread("t%d" %ts)
        t.start()
        t_lst.append(t)
        

    
    ed2 = time.time()
    print("cost time of Method2 is %f" %(ed2-st2))
    
    time.sleep(10)
    print("count of active thread = %d" %threading.active_count()) #输出活跃的线程数
```

### 4. GIL（Global Interpreter Lock， 全局解释器锁）

> 在非python环境中，单核情况下，同时只能有一个任务执行。多核时可以支持多个线程同时执行。但是在python中，无论有多少核，同时只能执行一个线程。究其原因，这就是由于GIL的存在导致的。

#### 什么是GIL & GIL是如何产生的

​    GIL的全称是Global Interpreter Lock(全局解释器锁)，来源是python设计之初的考虑，为了**数据安全所**做的决定。某个线程想要执行，必须先拿到GIL，我们可以把GIL看作是“通行证”，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。GIL只在cpython中才有，因为cpython调用的是c语言的原生线程，所以他不能直接操作cpu，只能利用GIL保证同一时间只能有一个线程拿到数据。而在pypy和jpython中是没有GIL的。

#### Python多线程执行过程

> python在使用多线程的时候，调用的是c语言的原生线程

1. 拿到公共数据
2. 申请gil
3. python解释器调用os原生线程
4. os操作cpu执行运算
5. 当该线程执行时间到后，无论运算是否已经执行完，gil都被要求释放
6. 进而由其他进程重复上面的过程
7. 等其他进程执行完后，又会切换到之前的线程（从他记录的上下文继续执行）
   整个过程是每个线程执行自己的运算，当执行时间到就进行切换（context switch）

#### 存在问题

1. CPU密集型代码(各种循环处理、计算等等)，在这种情况下，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对CPU密集型代码并不友好；
2. IO密集型代码(文件处理、网络爬虫等涉及文件读写的操作)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好；
3. python下想要充分利用多核CPU，就用多进程。因为每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)

### 5. 线程通信(线程安全)

#### 线程锁

1. 一个进程所含的不同线程间共享内存，这就意味着任何一个变量都可以被任何一个线程修改，<u>因此线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了</u>。如果不同线程间有共享的变量，其中一个方法就是在修改前给其上一把锁lock，确保一次只有一个线程能修改它。线程锁用于锁定资源
2. 由于线程之间是进行随机调度，如果有多个线程同时操作一个对象，如果没有很好地保护该对象，会造成程序结果的不可预期，我们也称此为“线程不安全”

##### 互斥锁 mutex

> 为解决线程不安全而产生，线程在执行时，独占资源，执行结束后，释放资源；**本质上，让操作原子化**

##### 递归锁

RLcok类的用法和Lock类一模一样，但它支持嵌套，，在多个锁没有释放的时候一般会使用RLcok类

```python
import threading

def run(n):
    lock.acquire()  #获取锁
    global num
    num += 1
    lock.release()  #释放锁

lock  = threading.Lock()     #实例化一个锁对象
rlock = threading.RLock()

num = 0
t_obj = []  

for i in range(20000):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.start()
    t_obj.append(t)

for t in t_obj:
    t.join()

print("num: %d" %num)
```



#### 信号量(BoundedSemaphore类)

> 互斥锁同时只允许一个线程更改数据，而**Semaphore是同时允许一定数量的线程更改数据** ，比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。

```python
import threading
import time


def run(n):
    semaphore.acquire()   #加锁
    time.sleep(1)
    print("run the thread:%s\n" % n)
    semaphore.release()     #释放


num = 0
semaphore = threading.BoundedSemaphore(5)  # 最多允许5个线程同时运行

for i in range(22):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.start()

while threading.active_count() != 1:
    pass  # print threading.active_count()
else:
    print('-----all threads done-----')
```

#### 事件(Event类)

>  python线程的**事件**用于主线程控制其他线程的执行，事件是一个简单的线程**同步**对象，其主要提供以下几个方法：
>
> | 方法   | 注释                                                 |
> | ------ | ---------------------------------------------------- |
> | clear  | 将flag设置为“False”                                  |
> | set    | 将flag设置为“True”                                   |
> | is_set | 判断是否设置了flag                                   |
> | wait   | 会一直监听flag，如果没有检测到flag就一直处于阻塞状态 |
>
> 事件处理的机制：全局定义了一个“Flag”，当flag值为“False”，那么event.wait()就会阻塞，当flag值为“True”，那么event.wait()便不再阻塞。
>
> QA：和互斥锁有什么差异？

```python
#利用Event类模拟红绿灯
import threading
import time

event = threading.Event()


def lighter():
    count = 0
    event.set()     #初始值为绿灯
    while True:
        if 5 < count <=10 :
            event.clear()  # 红灯，清除标志位
            print("\33[41;1mred light is on...\033[0m")
        elif count > 10:
            event.set()  # 绿灯，设置标志位
            count = 0
        else:
            print("\33[42;1mgreen light is on...\033[0m")

        time.sleep(1)
        count += 1

def car(name):
    while True:
        if event.is_set():      #判断是否设置了标志位
            print("[%s] running..."%name)
            time.sleep(1)
        else:
            print("[%s] sees red light,waiting..."%name)
            event.wait()
            print("[%s] green light is on,start going..."%name)

light = threading.Thread(target=lighter,)
light.start()

car = threading.Thread(target=car,args=("MINI",))
car.start()
```



## Python多进程

> 每个进程都是由父进程提供的。每启动一个子进程就从父进程克隆一份数据，但是进程之间的数据本身是不能共享的

```python
from multiprocessing import Process
import os
 
def info(title):
    print(title)
    print('module name:', __name__)
    print('parent process:', os.getppid())  #获取父进程id
    print('process id:', os.getpid())   #获取自己的进程id
    print("\n\n")
 
def f(name):
    info('\033[31;1mfunction f\033[0m')
    print('hello', name)
 
if __name__ == '__main__':
    info('\033[32;1mmain process line\033[0m')
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
```

### 进程通信

> 由于进程之间数据是不共享的，所以不会出现多线程GIL带来的问题。多进程之间的通信通过Queue()或Pipe()来实现

> 为什么需要通信，数据不能共享
> 如何通信，Queue或Pipe

#### Queue



#### Pipe

​        Pipe的本质是进程之间的数据传递，而不是数据共享，这和socket有点像。pipe()返回两个连接对象分别表示管道的两端，每端都有send()和recv()方法。如果两个进程试图在同一时间的同一端进行读取和写入那么，这可能会损坏管道中的数据。

```

```

#### Manager

​        通过Manager可实现进程间数据的共享。Manager()返回的manager对象会通过一个服务进程，来使其他进程通过代理的方式操作python对象。manager对象支持 `list`, `dict`, `Namespace`, `Lock`, `RLock`, `Semaphore`, `BoundedSemaphore`, `Condition`, `Event`, `Barrier`, `Queue`, `Value` ,`Array`



### 进程同步

> 数据输出的时候保证不同进程的输出内容在同一块屏幕正常显示，防止数据乱序的情况。

```python
from multiprocessing import Process, Lock
 
def f(l, i):
    l.acquire()
    try:
        print('hello world %d' %i)
    finally:
        l.release()

def ff(i):
    try:
        print('hello world %d' %i)
    finally:
        pass
 

if __name__ == '__main__':
    lock = Lock()
 
    for num in range(10):
        Process(target=f, args=(lock, num)).start()
        
    for num in range(10):
        Process(target=ff, args=(num, )).start()
```



### 进程池

​        由于进程启动的开销比较大，使用多进程的时候会导致大量内存空间被消耗。为了防止这种情况发生可以使用进程池，（由于启动线程的开销比较小，所以不需要线程池这种概念，多线程只会频繁得切换cpu导致系统变慢，并不会占用过多的内存空间）

进程池中常用方法：

- `apply()` 同步执行（串行）
- `apply_async()` 异步执行（并行）
- `terminate()` 立刻关闭进程池
- `join()` 主进程等待所有子进程执行完毕。必须在close或terminate()之后
- `close()` 等待所有进程结束后，才关闭进程池

```python
from  multiprocessing import Process,Pool
import time
 
def Foo(i):
    time.sleep(2)
    return i+100
 
def Bar(arg):
    print('-->exec done:',arg)
 
pool = Pool(5)  #允许进程池同时放入5个进程
 
for i in range(10):
    pool.apply_async(func=Foo, args=(i,),callback=Bar)  #func子进程执行完后，才会执行callback，否则callback不执行（而且callback是由父进程来执行了）
    #pool.apply(func=Foo, args=(i,))
 
print('end')
pool.close()
pool.join() #主进程等待所有子进程执行完毕。必须在close()或terminate()之后。
```




## Python多线程、多进程框架
> 基于进程池
>
> 基于MapReduce的思维去设计算法



## 参考资料

1. [搞定python多线程和多进程](https://www.cnblogs.com/whatisfantasy/p/6440585.html)
3. [python多进程和多线程看这一篇就够了](https://blog.csdn.net/Victor2code/article/details/109005171)

4. [Python进程间通信的2种实现方法（Queue和Pipe）](http://c.biancheng.net/view/2635.html)