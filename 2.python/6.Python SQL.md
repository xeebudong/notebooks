## 建表

pass

## 增

pass

## 删

> 删除行、列
>
> pandas.DataFrame.drop¶
>
> DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')
>
> - labels，single label or list-like，Index or column labels to drop.
>
> - axis，{0 or ‘index’, 1 or ‘columns’}, default 0
>   Whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’).
>
> - index，single label or list-like
>   ***Alternative*** to specifying axis (labels, axis=0 is equivalent to index=labels).
>
> - columns single label or list-like
>   ***Alternative*** to specifying axis (labels, axis=1 is equivalent to columns=labels).
>
> - level， int or level name, optional
>   For MultiIndex, level from which the labels will be removed.
>
> - inplace，bool, default False
>   If False, return a copy. Otherwise, do operation inplace and return None.
>
> - errors，{‘ignore’, ‘raise’}, default ‘raise’
>   If ‘ignore’, suppress error and only existing labels are dropped.

```python
import pandas as pd
df = pd.DataFrame(np.arange(12).reshape(3, 4),
                  columns=['A', 'B', 'C', 'D'])

# 删除列
df.drop(labels  =['B', 'C']) # 无法正常执行，函数默认为axis=0,即删除行，找不到行
/* 要么显示的指定columns，要么设置axis=1 */
df.drop(columns =['B', 'C'])
df.drop(['B', 'C'], axis=1)

# 按条件删除列，比如如果B列中，有值为2(异常值)则删除之，这个很少有实际的应用场景
df.drop(columns= ["B" if (df["B"]==2).any() else "Undo"], errors='ignore')

# 删除行
df.drop(labels = [0])

# 按条件删除行，比如删除B列大于2的行
# 本质是给index赋值
df.drop(df[df['B']>2].index)
df.drop(labels=df[df['B']>2].index)
df.drop(index=df[df['B']>2].index)
```

## 改

### 修改名称

> [pandas.DataFrame.rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html)
>
> DataFrame.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')
>
> - mapper，dict-like or function
>   Dict-like or function transformations to apply to that axis’ values. **Use either mapper and axis to specify the axis to target with mapper, or index and columns**. 使用mapper配合axis，或者index\columns均可实现
>
> - index，dict-like or function
>   Alternative to specifying axis (mapper, axis=0 is equivalent to index=mapper).
>
> - columns，dict-like or function
>   Alternative to specifying axis (mapper, axis=1 is equivalent to columns=mapper).
>
> - axis，{0 or ‘index’, 1 or ‘columns’}, default 0
>   Axis to target with mapper. Can be either the axis name (‘index’, ‘columns’) or number (0, 1). The default is ‘index’.
>
> - copy，bool, default True
>   Also copy underlying data.
>
> - inplace，bool, default False
>   Whether to return a new DataFrame. If True then value of copy is ignored.
>
> - level，int or level name, default None
>   In case of a MultiIndex, only rename labels in the specified level.
>
> - errors，{‘ignore’, ‘raise’}, default ‘ignore’
>   If ‘raise’, raise a KeyError when a dict-like mapper, index, or columns contains labels that are not present in the Index being transformed. If ‘ignore’, existing keys will be renamed and extra keys will be ignored

```python
import pandas as pd
df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})

df.rename(mapper={"A":"alpha", "B":"beta"}, axis=1)
df.rename(columns={"A":"alpha", "B":"beta"})

df.rename(mapper={0:100})
df.rename(index={0:100})
```

### 修改值：修改列、修改cell

> 先熟悉查的部分

#### 查询及修改

> df.loc[df.sex == 'Male', 'sex'] = 'Leone'



#### `DataFrame.replace`**(***to_replace=None***,** *value=None***,** *inplace=False***,** *limit=None***,** *regex=False***,** *method='pad'***)**[_](https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/core/frame.py#L4511-L4528)



#### pandas.where



#### pandas.mask

```python
import pandas as pd
df = pd.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
```



## 查\筛选

### ix\iloc\iat\loc\at

1. ix，混用pos和index，已经被官方弃用，Q：为什么会被弃用？(simple is more)
2. iloc(通过行号索引行数据) \ loc(通过行标签索引数据)，可定位到行、列或者cell
3. at\iat，通过标签或行号获取**某个数值的具体位置**， 定位到cell，据说更快，因此，如果是要查找或修改dataframe中某个cell的具体值，建议使用at\iat
4. 直接索引df[]， 只能进行**行行选择**或者选择**列**，不能同时选择行列，根据列名查找列的时候，df[]方法很常用

> [Pandas DataFrame的loc、iloc、ix和at/iat浅析](https://www.jianshu.com/p/199a653e9668)

区别：

​	iloc vs loc \ iat vs at

​	at vs loc \ iat vs iloc

```python
import pandas as pd

df=pd.DataFrame(np.arange(12).reshape(4,3),columns=list('abc'),index=list('defg'))

# 查找某cell的数值
df.ix[1, 1]
df.iloc[1, 1]
df.iat[1, 1]

df.loc['d', 'c']
df.at['d', 'c']

# 查找某行
df.ix['d',:]
df.loc['d',:]
df.loc[df["a"]>1] # 按条件查找行
df.iloc[0,:]
df[0:2] 		  # 只能选择行行，选择第1行到第2行, df[0]就报错
df["d":"f"] 	  # 只能选择行行，选择第1行到第2行, df[0]就报错

# 查找某列或多列
df.ix[:, "a"]
df.loc[:, "a"]
df.iloc[:, 0]
df["a"] 
df[["a", "b"]] 
```

### 按数据类型查找

> [pandas.DataFrame.select_dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)
>
> DataFrame.select_dtypes(include=None, exclude=None)
>
> - include, excludescalar or list-like
>   A selection of dtypes or strings to be included/excluded. At least one of these parameters must be supplied, ***include*** is default

```python
import pandas as pd

df = pd.DataFrame({'a': [1, 2] * 3,
                   'b': [True, False] * 3,
                   'c': [1.0, 2.0] * 3})
df.select_dtypes("bool")
df.select_dtypes("int64")
df.select_dtypes("float")
df.select_dtypes(include='number') # 数字型
```

python 支持的数据类型

1. float \ float64
2. int  \ int64
3.  bool
4. datetime64[ns]
5. datetime64[ns, tz] 
6. timedelta[ns] 
7.  category 
8. object 

### 按条件查找(最小、最大索引)

> argmax\argmin & idxmax\idxmin
>
> 基本一致，argmax要带后缀.values
>
> Returns the indices of the maximum values along an axis

1. 找出A列中最大数值所在的行
2. 找出每行最大数值所在的列(例如，要找出商户每一个产品在哪一天销量最大，表为col-日期，row-商品)

```python
import pandas as pd

df = pd.DataFrame({
        "name":["A", "B", "A", "C", "B"]
        , "gain1":[1, 3, 2, 3, 2]
        , "gain2":[2, 5, 9, 0, 5]
        })

df.values.argmax(axis=0) 						# axis=1为行，axis=0为列，每列最大值所在的行
df[["gain1", "gain2"]].values.argmax(axis=1) 	# 每行最大值所在的列

df[["gain1", "gain2"]].idxmax(axis=1)			
```

### 筛选

#### [pd.where](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html)

#### [pd.query](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)

> `DataFrame.query`(, *inplace=False*, ***kwargs*)[[source\]](https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/core/frame.py#L3316-L3478)
>
> - Query the columns of a DataFrame with a boolean expression.

> - **expr**, str, The query string to evaluate
>
> - **inplace**, bool，Whether the query should modify the data in place or return a modified copy.
>
> - ***\*kwargs**

### Top N-largest \ N-smallest

> pandas.DataFrame.nlargest \ nsmallest
>
> `DataFrame.nlargest`(*n*, *columns*, *keep='first'*)[[source\]](https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/core/frame.py#L5687-L5794)
>
> Return the first n rows ordered by columns in descending order.
>
> - **n**, int, Number of rows to return.
>
> - **columns**, label or list of labels，Column label(s) to order by.
>
> - **keep**， {‘first’, ‘last’, ‘all’}, default ‘first’
>
>   Where there are duplicate values:
>
>   - first : prioritize the first occurrence(s)
>
>   - last : prioritize the last occurrence(s)
>
>   - `all`do not drop any duplicates, even it means
>
>     selecting more than n items.

```python
df = pd.DataFrame({'population': [59000000, 65000000, 434000,
                                  434000, 434000, 337000, 11300,
                                  11300, 11300],
                   'GDP': [1937894, 2583560 , 12011, 4520, 12128,
                           17036, 182, 38, 311],
                   'alpha-2': ["IT", "FR", "MT", "MV", "BN",
                               "IS", "NR", "TV", "AI"],
                  'District':["At", "At", "Brk", "Brk", "At", "At", "Kp", "Brk", "Kp"]},
                  index=["Italy", "France", "Malta",
                         "Maldives", "Brunei", "Iceland",
                         "Nauru", "Tuvalu", "Anguilla"])

df.nlargest(3, 'population')
df.nlargest(3, 'population', keep="all")
df.nlargest(3, ['population', 'GDP'])

# 分组求top，求出不同District中，GDP排名前2的国家
# method1
df.groupby("District", as_index=None).apply(lambda x:x.nlargest(2, "GDP"))

# method2
df.assign(rn=df.groupby("District")["GDP"].rank(method="first", ascending=False)).query('rn<3').sort_values(['District', 'rn'])

# method3
df.assign(rn=df.sort_values(by=["GDP"], ascending=False).groupby("District").cumcount()+1).query('rn<3').sort_values(['District', 'rn'])
```

## 连接 merge concat

### concat

`pandas.concat`**(***objs***,** *axis=0***,** *join='outer'***,** *ignore_index=False***,** *keys=None***,** *levels=None***,** *names=None***,** *verify_integrity=False***,** *sort=False***,** *copy=True***)**[[source\]](https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/core/reshape/concat.py#L82-L298)[¶](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat)



### merge \ [merge_ordered](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_ordered.html) \ [merge_asof](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_asof.html)

`pandas.merge`**(***left***,** *right***,** *how='inner'***,** *on=None***,** *left_on=None***,** *right_on=None***,** *left_index=False***,** *right_index=False***,** *sort=False***,** *suffixes=('_x', '_y')***,** *copy=True***,** *indicator=False***,** *validate=None***)**[[source\]](https://github.com/pandas-dev/pandas/blob/v1.2.1/pandas/core/reshape/merge.py#L57-L89)[¶](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html#pandas.merge)

| Merge method | SQL Join Name      | Description                               |
| :----------- | :----------------- | :---------------------------------------- |
| `left`       | `LEFT OUTER JOIN`  | Use keys from left frame only             |
| `right`      | `RIGHT OUTER JOIN` | Use keys from right frame only            |
| `outer`      | `FULL OUTER JOIN`  | Use union of keys from both frames        |
| `inner`      | `INNER JOIN`       | Use intersection of keys from both frames |

### [join](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)



> [Merge, join, concatenate and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)

## 分组 groupby

### 排序

[组内排序](https://zhuanlan.zhihu.com/p/30277559)

```python
import pandas as pd

df = pd.DataFrame([['A',1],['A',3],['A',2],['B',5],['B',9]], columns = ['name','score'])
print(df)

# 先分组再排序
print(df.groupby('name', as_index=False).apply(lambda x: x.sort_values('score', ascending=False)))

# 先排序再分组，直接排序就好了
```

### 组内排序，并加上序号

1. [cumcount](http://www.imooc.com/wenda/detail/566046)
2. [groupby+rank](https://blog.csdn.net/u010652755/article/details/90760692)

```python
import pandas as pd

df = pd.DataFrame([['A',1],['A',3],['A',2],['B',5],['B',9]], columns = ['name','score'])

# 1. cumcount
df.sort_values(by=["score"], inplace=True)
df['seq'] = df.groupby(['name']).cumcount() + 1

# 2. groupby + rank
df["seq3"] = df.groupby(["name"])["score"].rank(ascending=True, method="min")
```

### 组内求和

```python
import pandas as pd

df = pd.DataFrame({'name':['Jack','Alex','Bob','Nancy','Mary','Alice','Jerry','Wolf'],
              'course':['Chinese','Math','Math','Chinese','Math','English','Chinese','English'],
              'grade':[1,1,2,2,2,2,3,3],
              'score':[85,95,91,78,89,60,87,79]})

# 仅用groupby("name")统计各学生 语文、数据、英语的成绩
df.groupby(["name"])["score"].sum()
df.groupby(["course"])["score"].sum()
```

### [组内累增](https://stackoverflow.com/questions/22650833/pandas-groupby-cumulative-sum)

```python
import pandas as pd

df = pd.DataFrame({
        "name":["A", "B", "A", "C", "B"]
        , "gain1":[1, 3, 2, 3, 2]
        , "gain2":[2, 5, 9, 9, 5]
        })
df.sort_values(by=["name"], inplace=True)

df[["gain1_cum", "gain2_cum"]] = df.groupby("name")[["gain1", "gain2"]].cumsum()
```

### [组内偏移](https://blog.csdn.net/qq_16949707/article/details/105037058)

```python
import pandas as pd

df = pd.DataFrame({
        "name":["A", "B", "A", "C", "B"]
        , "gain1":[1, 3, 2, 3, 2]
        , "gain2":[2, 5, 9, 9, 5]
        })
df.sort_values(by=["name"], inplace=True)

# 向下偏移1行
df[['gain1_shift', 'gain2_shift']] = df.groupby(['name'])['gain1', 'gain2'].shift(1)
```

### 组内字符串连接

df.groupby("id")["skill"].apply(lambda x:x.str.cat(sep=":")).reset_index()

## 赋值

1. pandas 同时给多列赋值

   > 使用result_type=“expand”
   >
   > data.apply(lambda x:('数据','月份'),axis=1,result_type='expand')

   ```python
   import pandas as pd
   
   chengji=[[100,95,100,99],[90,98,99,100],[88,95,98,88],[99,98,97,87],[96.5,90,96,85],[94,94,93,91],[91, 99, 92, 87], [85, 88, 85, 90], [90, 92, 99, 88], [90, 88, 89, 81], [85, 89, 89, 82], [95, 87, 86, 88], [90, 97, 97, 98], [80, 92, 89, 98], [80, 98, 85, 81], [98, 88, 95, 92]]
   data=pd.DataFrame(chengji,columns=['语文','英语','数学','政治'])
   print (data)
   # data1=data[['数学','语文','英语','政治']]                               #排序
   # data1=data1.reset_index(drop=True)                    #序列重建
   # data1.index.names=['序号']                                 #序列重命名
   # data1.index=data1.index+1                             #序列从1开始
   # print (data1)
   data=pd.DataFrame(chengji,columns=['语文','英语','数学','政治'],index=[i for i in range(1,len(chengji)+1)])
   print (data)
   data[['合计','平均']]=data.apply(lambda x: (x.sum(), x.sum()/4),axis=1,result_type='expand')
   print (data[:])
   
   data=pd.DataFrame(chengji,columns=['语文','英语','数学','政治'],index=[i for i in range(1,len(chengji)+1)])
   print (data)
   data[['合计','平均']]=data.apply(lambda x:('数据','月份'),axis=1,result_type='expand')
   print (data[:])
   ```

   

2. 

## 空值填充

1. 前向填充、后向填充

   ```python
   import pandas as pd
   import numpy as np
   
   df = pd.DataFrame([[np.NaN, '1-5'], [np.NaN, '26-100'], ['Yes', 'More than 1000'], ['No', '26-100'], ['Yes', '1-5']], columns=['self_employed', 'no_employees'])
   
   df["self_employed"].bfill()
   ```

   

2. 按条件填充

3. 

4. 

## 透视表

1. [Reshaping and pivot tables¶](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)

- pivot

- pivot_table

- crosstab

  > 显示百分比
  >
  > crs = pd.crosstable(df["row"], df["col"], normalize="columns")
  >
  > - normailize 为 columns、index、all，columns为每一列相加为100%，index每一行相加为100%
  >
  > from seaborn import heatmap
  >
  > heatmap(crs, fmt = '.2%')

## 函数

### apply

### applymap

### agg

### filter

### [transform](https://www.jianshu.com/p/509d7b97088c)

```python
import pandas as pd

df = pd.DataFrame({"A":["A", "B", "D", "A", "D"], "B":[1, 3, 2, 6, 5], "cnt":[1, 3, 2, 6, 5]})
stat_df = df.groupby(["A"], as_index = None)["cnt"].transform(lambda x:x.sum())
stat_df
```



## 参考

1. [让你像写SQL一样做数据分析](https://blog.csdn.net/cdk1015/article/details/78744709)
2. [A Comprehensive Guide to Data Exploration](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/)